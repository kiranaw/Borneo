import _file_.model._

def feedingBudgetTest(d: Seq[Double]) = klDivergence(probabilityDistribution(d,10), Seq(0.04746835443037975, 0.03164556962025317, 0.028481012658227847, 0.08227848101265822, 0.0759493670886076, 0.09177215189873418, 0.18037974683544303, 0.23734177215189872, 0.18670886075949367, 0.0379746835443038))
def travelBudgetTest(d: Seq[Double]) = klDivergence(probabilityDistribution(d,10), Seq(0.2120253164556962, 0.40822784810126583, 0.2120253164556962, 0.08860759493670886, 0.03481012658227848, 0.015822784810126583, 0.00949367088607595, 0.0, 0.00949367088607595, 0.00949367088607595)) //6	73	116	80	23	7	6	3	1	1
def restBudgetTest(d: Seq[Double]) = klDivergence(probabilityDistribution(d,10), Seq(0.08860759493670886, 0.24050632911392406, 0.3670886075949367, 0.18670886075949367, 0.060126582278481014, 0.022151898734177215, 0.0189873417721519, 0.006329113924050633, 0.006329113924050633, 0.0031645569620253164)) //6	73	116	80	23	7	6	3	1	1

def activityBudgetFitness(d: Seq[Array[Double]]) =
Seq(
    feedingBudgetTest(d.map(_(6))),
    travelBudgetTest(d.map(_(7))),
    restBudgetTest(d.map(_(8)))
    ).average

val replicate = 
  Replication(
    evaluation = model, 
    seed = seed, 
    sample = 10,
    aggregation = Seq(
      walk aggregate median, 
      sway aggregate median,
      brachiation aggregate median,
      climb aggregate median, 
      descent aggregate median, 
      travelDistance aggregate median,
      feedingBudget aggregate median, 
      travellingBudget aggregate median,
      restingBudget aggregate median,
      totalEnergyIntake aggregate median,
      energyExpenditure aggregate median
    )
  )

val resultLine = Val[Array[Double]]

val tupleTask = ScalaTask("""
  val resultLine = 
    Array(walk, sway, brachiation, climb, descent, travelDistance, feedingBudget, travellingBudget, restingBudget, totalEnergyIntake, energyExpenditure) 
""") set (
  (inputs, outputs) += (walk, sway, brachiation, climb, descent, travelDistance, feedingBudget, travellingBudget, restingBudget, totalEnergyIntake, energyExpenditure), 
  outputs += (resultLine)
)

val env =
  SLURMEnvironment(
    "widyastu",
    "taurus.hrsk.tu-dresden.de",
    workDirectory = "/tmp",
    //sharedDirectory = "/projects/p036/p_peatfire",
    time = 2 hour,
    memory = 3000 megabytes,
    openMOLEMemory = 2000 megabytes,
    reservation = "p_peatfire_386",
    nodes = 1,
    threads = 2
  )

def profile(variable: Val[Double]) =
ProfileEvolution(
  evaluation = replicate -- tupleTask,
  objective = Seq(resultLine aggregate (activityBudgetFitness _) as "budgetFit"),
  reject = "climbSpeed > (descentSpeed - 0.2) || brachiationSpeed > swaySpeed || walkSpeed > swaySpeed", //, "brachiationSpeed < swaySpeed", "walkSpeed < swaySpeed - 0.2" ),
  profile = Seq(variable),
  genome = Seq(
     //bodyWeight in (30.0 to 45.0),
    energyIntake in (0.01 to 10.0),
    energyGain in (0.1 to 500.0),
   // initialSatiation in (-500.0 to 500.0),
    basalEnergy in (0.1 to 15.0),
    brachiationSpeed in (0.1 to 2.0),
    swaySpeed in (0.1 to 2.0),
    climbSpeed in (0.1 to 2.0),
    descentSpeed in (0.1 to 2.0),
    walkSpeed in (0.1 to 1.0)
    //month
  ),
  parallelism = 10000,
  termination = 1000000, //number of evaluated individuals
  stochastic = Stochastic(seed = seed, sample = 50),
  distribution = Island(5 minutes)
) hook (workDirectory / s"results_profile_test0/${variable.name}", filter = Seq(resultLine), frequency = 1000) on env by 10

EmptyTask() -- (profile(energyIntake))
