import _file_.model._

def outside(v: Seq[Double], min: Double, max: Double) = v.count(v => v < min | v > max).toDouble / v.size
def outsideP(v: Seq[Double], target: Double, p: Double = 0.9) = outside(v, target - (target * p), target + (target * p))

def dailyTravelDistanceFit(v: Seq[Double]) = outsideP(v, 769)
def totalEnergyExpenditureFit(v: Seq[Double]) = outsideP(v, 1476)
def totalEnergyIntakeFit(v: Seq[Double]) = outsideP(v, 3015)

def energyFit(d: Seq[Array[Double]]) =
  Seq(
   dailyTravelDistanceFit(d.map(_(5))),
   totalEnergyExpenditureFit(d.map(_(10))),
   totalEnergyIntakeFit(d.map(_(9)))
  ).average
 

def frequencyOfSwayFit(d: Seq[Double]) = outsideP(d, 20.2)  
def frequencyOfBrachiateFit(d: Seq[Double]) = outsideP(d, 51.2)
def frequencyOfWalkFit(d: Seq[Double]) = outsideP(d, 12.5)
def frequencyOfClimbFit(d: Seq[Double]) = outsideP(d,10.5)
def frequencyOfDescentFit(d: Seq[Double]) = outsideP(d, 5.5)

def frequencyOfMoveFit(d: Seq[Array[Double]]) =
  Seq(
    frequencyOfSwayFit(d.map(_(1))),
    frequencyOfBrachiateFit(d.map(_(2))),
// in this world setting, orangutan would not walk <-   frequencyOfWalkFit(d.map(_(0))),
    frequencyOfClimbFit(d.map(_(3))),
    frequencyOfDescentFit(d.map(_(4))),
  ).average


def feedingBudgetFit(d: Seq[Double]) = outsideP(d, 50.6)
def travelingBudgetFit(d: Seq[Double]) = outsideP(d, 16.6)
def restingBudgetFit(d: Seq[Double]) = outsideP(d, 31.3)


def budgetFit(d: Seq[Array[Double]]) =
  Seq(
    feedingBudgetFit(d.map(_(6))),
    travelingBudgetFit(d.map(_(7))),
    restingBudgetFit(d.map(_(8)))
  ).average

val replicate = 
  Replication(
    evaluation = model, 
    seed = seed, 
    sample = 10,
    aggregation = Seq(
      walk aggregate median, 
      sway aggregate median,
      brachiation aggregate median,
      climb aggregate median, 
      descent aggregate median, 
      travelDistance aggregate median,
      feedingBudget aggregate median, 
      travellingBudget aggregate median,
      restingBudget aggregate median,
      totalEnergyIntake aggregate median,
      energyExpenditure aggregate median
    )
  )

val resultLine = Val[Array[Double]]

val tupleTask = ScalaTask("""
  val resultLine = 
    Array(walk, sway, brachiation, climb, descent, travelDistance, feedingBudget, travellingBudget, restingBudget, totalEnergyIntake, energyExpenditure) 
""") set (
  (inputs, outputs) += (walk, sway, brachiation, climb, descent, travelDistance, feedingBudget, travellingBudget, restingBudget, totalEnergyIntake, energyExpenditure), 
  outputs += (resultLine)
)

val env =
  SLURMEnvironment(
    "widyastu",
    "taurus.hrsk.tu-dresden.de",
    wallTime = 1 hour,
    memory = 2100 megabytes,
    openMOLEMemory = 1500 megabytes,
 //   reservation = "p_peatfire_288",
    nodes = 1,
    threads = 1,
    workDirectory = "/tmp"
  )

NSGA2Evolution(
  evaluation = replicate -- tupleTask,
  genome = Seq(
    bodyWeight in (30.0 to 45.0),
    energyIntake in (0.1 to 10.0),
    energyGain in (1.0 to 400.0),
    initialSatiation in (-500.0 to 500.0),
    basalEnergy in (1.0 to 1.5),
    brachiationSpeed in (0.5 to 2.0),
    swaySpeed in (0.5 to 2.0),
    climbSpeed in (0.5 to 2.0),
    descentSpeed in (0.5 to 2.0),
    walkSpeed in (0.5 to 1.0)
  ),
  objective = Seq(
    resultLine aggregate (energyFit _) as "energyFit",
    resultLine aggregate (frequencyOfMoveFit _) as "frequencyOfMoveFit",
    resultLine aggregate (budgetFit _) as "budgetFit"
  ),
  parallelism = 500,
  termination = 500000,
  stochastic = Stochastic(seed = seed, sample = 50),
  distribution = Island(5 minutes)
) hook (workDirectory / "results_25_05_1911", filter = Seq(resultLine), frequency = 100) on env
